// ----------------------------------------------------------------------------
// Copyright (C) 2015 Louise A. Dennis,  Michael Fisher and Koen Hindriks
// 
// This file is part of GOAL (AIL version) - GOAL-AIL
//
// GOAL-AIL is free software; you can redistribute it and/or
// modify it under the terms of the GNU Lesser General Public
// License as published by the Free Software Foundation; either
// version 3 of the License, or (at your option) any later version.
// 
// GOAL-AIL is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
// Lesser General Public License for more details.
// 
// You should have received a copy of the GNU Lesser General Public
// License along with GOAL-AIL if not, write to the Free Software
// Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
// 
// To contact the authors:
// http://www.csc.liv.ac.uk/~lad
//----------------------------------------------------------------------------
package goal.semantics.operationalrules;

import goal.semantics.AbstractGoalStage;
import goal.semantics.GOALAgent;
import goal.semantics.GOALRC;
import goal.semantics.GOALRCStage;
import goal.syntax.ActionRule;
import goal.syntax.GOALModule.RuleEvaluationOrder;
import goal.syntax.ActionCombo;
import goal.syntax.MentalState;
import goal.syntax.GOALModule;

import java.util.Iterator;
import java.util.List;
import java.util.LinkedList;
import java.util.ArrayList;
import java.util.Set;
import java.util.Collections;

import ail.semantics.AILAgent;
import ail.semantics.OSRule;
import ail.syntax.Unifier;
import ail.syntax.Plan;
import ail.syntax.PlanLibrary;
import ail.syntax.ApplicablePlan;

public class SelectRule implements OSRule {
	GOALModule m;
	
    /**
     * The set of rules in this container.
     */
    private PlanLibrary rules;
    /**
     * Determines how the next action to be executed is selected.
     */
    private RuleEvaluationOrder ruleOrder;
    
    public SelectRule() {
    	this.ruleOrder = RuleEvaluationOrder.LINEAR;
    }
    
    public void setModule(GOALModule m) {
    	this.m = m;
    	rules = m.getRules();
    	ruleOrder = m.getRuleOrder();
    }
    
    public void setRules(List<Plan> plans) {
    	for (Plan p: plans) {
    		rules.add((ActionRule) p);
    	}
    }

    public SelectRule(PlanLibrary rules, RuleEvaluationOrder ruleOrder) {
            this.rules = rules;
            this.ruleOrder = ruleOrder;
    }
		
    /**
     * Returns the actions that can be performed in the agent's current mental
     * state (extracted from the run state).
     * <p>
     * Only supports linear and random rule evaluation orders, but not the 'all'
     * orders; i.e., linearall or randomall are not supported.
     * </p>
     * <p>
     * In case of the 'linear' modes only returns the options generated by the
     * first rule that is applicable. In case of the 'random' modes all options
     * for every rule that is applicable are returned.
     * </p>
     *
     * @param mentalState
     *            The mental state used for evaluating the action options.
     * @param debugger
     *            The current debugger.
     * @return A list of actions that may be performed in the given mental
     *         state, possibly empty.
     * @throws KRInitFailedException
     * @throws UnknownObjectException
     */
    @SuppressWarnings("fallthrough")
 /*   private final List<ActionCombo> getActionOptions(MentalState mentalState) {
            List<ActionCombo> actionOptions = new LinkedList<>();
            Set<Unifier> solutions;
            boolean finished = false;

            // Does not support linearall and randomall orders.
            switch (this.ruleOrder) {
            case LINEARALL:
            case RANDOMALL:
                    throw new UnsupportedOperationException(
                                    "Linear and random all are not"
                                                    + "supported by RuleSet.getOptions(RunState).");
            default:
                    // continue.
            } */

            /*
             * In case of 'linear' style evaluation find the first applicable rule
             * and return the options of that rule only; otherwise check all rules
             * and return the options for every rule that is applicable.
             */
            /*
             * In case of 'linear' style evaluation find the first applicable rule
             * and return the options of that rule only; otherwise check all rules
             * and return the options for every rule that is applicable.
             */
  /*          while(rules.getAllReactivePlans(a).hasNext()) {
                    // Evaluate the rule's condition.
                    solutions = new MentalStateConditionExecutor(rule.getCondition())
                    .evaluate(mentalState, debugger);
                    // Listall rules need to be processed further.
               //     if (rule instanceof ListallDoRule) {
               //             solutions = getVarSubstitution((ListallDoRule) rule, solutions,
               //                             krInterface);
               //     }

                    // If condition holds, then check for action options;
                    // otherwise continue with next rule.
                    if (!solutions.isEmpty()) {
                            // Check options for each solution found for rule condition.
                            for (Unifier substitution : solutions) {
                                    // First, instantiate the rule's action by applying the
                                    // substitution found.
                                    ActionComboExecutor instantiatedAction = new ActionComboExecutor(
                                                    rule.getAction().applySubst(substitution));
                                    instantiatedAction.setContext(rule.getCondition()
                                                    .applySubst(substitution));
                                    // Second, check precondition and add all options for this
                                    // instantiation.
                                    actionOptions.addAll(instantiatedAction.getOptions(
                                                    mentalState, substitution, debugger));
                            }

                            // In case rule evaluation order is 'linear' do not evaluate any
                            // other rules
                            // if we have already found some action options.
                            if (actionOptions.size() > 0) {
                                    switch (this.ruleOrder) {
                                    case LINEAR:
                                    case LINEARADAPTIVE:
                                            finished = true;
                                    default:
                                            // continue.
                                    }
                            }

                            // If we're finished break out of the loop.
                            if (finished) {
                                    break;
                            }
:
                    }
              }

              return actionOptions;
      } */
    
    public void apply(AILAgent ag) {
        // Make a copy of the rules so we don't shuffle the original below.
        PlanLibrary rules = this.rules.copy();

        switch (this.ruleOrder) {
        case ADAPTIVE:
        case LINEARADAPTIVE:
            /*
             * For now there is no differentiation between adaptive and linear
             * adaptive options. In both cases, a 'random' action option will be
             * selected for execution by the learner.
             */
           // MentalState ms = runState.getMentalState();

         //   runState.incrementRoundCounter();

            /*
             * Get the learner to choose one action option, from the input list
             * of action options.
             */
        //    List<ActionCombo> options = getActionOptions(ms,
        //                    runState.getDebugger(), krInterface);

            // There are no possible options for actions to execute.
       //     if (options.isEmpty()) {
        //            break;
        //   }

            // Select an action
        //    ActionCombo chosen = runState.getLearner().act(
        //                    runState.getActiveModule().getName(), ms, options);

            /*
             * Now execute the action option TODO: context?!
             */
       //     result = new ActionComboExecutor(chosen).run(runState,
       //                     substitution, true);

            /*
             * Obtain the reward from the environment. Or, if the environment
             * does not support rewards, then create an internal reward based on
             * whether we have achieved all our goals or not.
             */
       //     boolean goalsEmpty = ms.getAttentionSet().getGoals().isEmpty();
            // runState should now have reward set.
        //    Double envReward = runState.getReward();
       //     double reward = (envReward != null) ? envReward : goalsEmpty ? 1.0
        //                    : 0.0;

         //   if (!goalsEmpty) {
                /* Update the learner with the reward from the last action */
        //        runState.getLearner().update(
        //                        runState.getActiveModule().getName(), ms, reward);
        //} else {
                /*
                 * If goals were achieved, then the final reward is calculated,
                 * and the learning episode finished, in RunState.kill() when
                 * the agent is killed.
                 */
        //}
        break;
        case RANDOM:
        	rules.shuffle();
        case LINEAR:
        	Iterator<ApplicablePlan> ruleIterator = rules.getAllReactivePlans(ag);
        	if (ruleIterator.hasNext()) {
        		m.setRule(ruleIterator.next());
        	}
        break;
        case RANDOMALL:
        	rules.shuffle();
        case LINEARALL:
        // Continue evaluating and applying rule as long as there are more,
        // and no {@link ExitModuleAction} has been performed.
   /*     	for (ActionRule rule : rules) {
                result.merge(new RuleExecutor(rule).run(runState, substitution));
                if (result.isModuleTerminated()) {
                        break;
                }
        	} */
        	break;
        default:
        	break;
        }
    }

	@Override
	public boolean checkPreconditions(AILAgent a) {
		// TODO Auto-generated method stub
		return true;
	}

	@Override
	public String getName() {
		// TODO Auto-generated method stub
		return null;
	}



}
